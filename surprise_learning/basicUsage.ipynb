{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise import model_selection\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split, cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x21a3ceb0358>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9371  0.9342  0.9298  0.9396  0.9418  0.9365  0.0042  \n",
      "MAE (testset)     0.7399  0.7371  0.7337  0.7384  0.7406  0.7379  0.0024  \n",
      "Fit time          3.31    3.29    3.32    3.32    3.32    3.31    0.01    \n",
      "Test time         0.11    0.15    0.11    0.10    0.14    0.12    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93713818, 0.9342457 , 0.92984112, 0.93959251, 0.94181479]),\n",
       " 'test_mae': array([0.73985849, 0.73705624, 0.73374078, 0.73844572, 0.74055128]),\n",
       " 'fit_time': (3.3071305751800537,\n",
       "  3.2941954135894775,\n",
       "  3.3192172050476074,\n",
       "  3.322118043899536,\n",
       "  3.3201229572296143),\n",
       " 'test_time': (0.10870885848999023,\n",
       "  0.15056800842285156,\n",
       "  0.10571694374084473,\n",
       "  0.10175132751464844,\n",
       "  0.13962745666503906)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVD()\n",
    "cross_validate(model, data, measures=['rmse', 'mae'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split and the fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9320816817244147"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVD()\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=10, shuffle=True)\n",
    "model.fit(trainset)\n",
    "pred = model.test(testset)\n",
    "accuracy.rmse(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9463  0.9436  0.9436  0.9449  0.9403  0.9437  0.0020  \n",
      "MAE (testset)     0.7522  0.7485  0.7459  0.7477  0.7463  0.7481  0.0022  \n",
      "Fit time          0.15    0.16    0.16    0.16    0.15    0.16    0.01    \n",
      "Test time         0.08    0.07    0.07    0.14    0.07    0.09    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94628852, 0.94364818, 0.9435601 , 0.94489797, 0.9402699 ]),\n",
       " 'test_mae': array([0.7522021 , 0.74851653, 0.74593583, 0.74772131, 0.74631545]),\n",
       " 'fit_time': (0.14760494232177734,\n",
       "  0.1576073169708252,\n",
       "  0.1625657081604004,\n",
       "  0.1605982780456543,\n",
       "  0.14663004875183105),\n",
       " 'test_time': (0.0758211612701416,\n",
       "  0.07277631759643555,\n",
       "  0.07380247116088867,\n",
       "  0.14259076118469238,\n",
       "  0.06879377365112305)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import BaselineOnly\n",
    "from surprise import Reader\n",
    "import os\n",
    "\n",
    "file_path = os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "cross_validate(BaselineOnly(), data, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load a dataset from a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Houlai\\Anaconda3\\envs\\TF2_GPU_PY36\\lib\\importlib\\_bootstrap.py:205: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Houlai\\Anaconda3\\envs\\TF2_GPU_PY36\\lib\\importlib\\_bootstrap.py:205: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dict = {'itemID': [1, 1, 1, 2, 2],\n",
    "                'userID': [9, 32, 2, 45, 'user_foo'],\n",
    "                'rating': [3, 2, 4, 3, 1]}\n",
    "df = pd.DataFrame(ratings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_foo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID  itemID  rating\n",
       "0         9       1       3\n",
       "1        32       1       2\n",
       "2         2       1       4\n",
       "3        45       2       3\n",
       "4  user_foo       2       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['userID', 'itemID', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.8481  1.0478  0.3203  0.2766  1.9844  1.0954  0.7253  \n",
      "MAE (testset)     1.8481  1.0478  0.3203  0.2766  1.9844  1.0954  0.7253  \n",
      "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.84805728, 1.04777679, 0.32027995, 0.27660912, 1.98443767]),\n",
       " 'test_mae': array([1.84805728, 1.04777679, 0.32027995, 0.27660912, 1.98443767]),\n",
       " 'fit_time': (0.0, 0.0, 0.000997304916381836, 0.0, 0.0),\n",
       " 'test_time': (0.000997304916381836, 0.0, 0.0, 0.0, 0.0)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df, reader)\n",
    "model = NormalPredictor()\n",
    "cross_validate(model, data, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cross-validation iterators\n",
    "For cross-validation, we can use the cross_validate() function that does all the hard work for us. But for a better control, we can also instanciate a cross-validation iterator, and make predictions over each split using the split() method of the iterator, and the test() method of the algorithm. Here is an example where we use a classical K-fold cross-validation procedure with 5 splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9381\n",
      "RMSE: 0.9235\n",
      "RMSE: 0.9416\n",
      "RMSE: 0.9368\n",
      "RMSE: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.938104942837033,\n",
       " 0.9235084141941013,\n",
       " 0.9415713497791371,\n",
       " 0.9368151342405137,\n",
       " 0.9336001494262185]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "model = SVD()\n",
    "kf = KFold(n_splits=5)\n",
    "rmse = []\n",
    "for trainset, testset in kf.split(data):\n",
    "    model.fit(trainset)\n",
    "    pred = model.test(testset)\n",
    "    rmse.append(accuracy.rmse(pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956063972717839\n",
      "{'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "param_grid = {'n_epochs': [5, 10, 20], 'lr_all': [0.002, 0.005, .01],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "gs.fit(data)\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': <surprise.prediction_algorithms.matrix_factorization.SVD at 0x27f4c992470>,\n",
       " 'mae': <surprise.prediction_algorithms.matrix_factorization.SVD at 0x27f59868f98>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit ('TF2_GPU_PY36': conda)",
   "language": "python",
   "name": "python36264bittf2gpupy36condabd0b351e206d41c0bd036f2b23435a37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
