**写在前面**：笔者前段时间又出差了，一周连续四天上线发版本，累成dog，于是公众号又停滞了。言归正传，本文谈的样本不均衡问题是机器学习中的常见问题，笔者之前几乎每次面试都会问到，这次好好梳理一下做个记录。

## 1 问题背景

机器学习中常常会遇到数据的**类别不平衡（class imbalance）**问题。以二分类问题为例，我们希望根据病人的一些检测指标预测病人是否得了某种罕见疾病。显然，根据所有历史数据，病人患这种罕见疾病的比例很低（不然咋叫罕见呢）。

在这种情况下，学习出好的分类器是很难的，得到的结论往往也是很具迷惑性的。因为如果一个分类器**总是**预测一个人未患罕见疾病，依然有高达99.9%的预测准确率（测试集与总体数据集同分布的情况下），看起来准确率很高，但却预测不出患病的病人。显然这种分类器是没有意义的，但它也反映了一个很重要的问题：**如何在类别不平衡的情况下评估分类器的性能？**

## 2 如何在类别不平衡的情况下评估分类器的性能？

对于平衡的数据，我们一般用准确率（accuracy）作为一般的评估标准。这种标准的默认假设前提是：**数据是平衡的，正例与反例的重要性一样，二分类器的阈值是0.5。**在这种情况下，用准确率来对分类器进行评估是合理的。

而当类别不平衡时，准确率就非常具有迷惑性，意义不大。下面给出几种主流的评估方法：

- ROC曲线，全名receiver operating characteristic curve，计算ROC曲线下的面积AUC是一种主流方法
- PR曲线，全名Precision-recall curve，和ROC有相似的地方，但定义不同，计算此曲线下的面积也是一种方法
- Precision@n是另一种方法，特制将分类阈值设定得到恰好n个正例时分类器的precision
- AP，全名Average precision，也叫做平均精度，主要描述了precision的一般表现，在异常检测中有时候会用
- 直接使用Precision也是一种想法，但需要调整分类器阈值（不要盲目使用0.5）

### 2.1 ROC曲线和AUC

ROC曲线，即受试者工作特征曲线（receiver operating characteristic curve），是反映敏感性和特异性连续变量的综合指标。

**首先**，在试图弄懂AUC和ROC曲线之前，一定，一定要彻底理解**混淆矩阵**的定义！！！

混淆矩阵中有着Positive、Negative、True、False的概念，其含义如下：

- **称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）。**
- **预测正确的为True（真），预测错误的为False（假）。**

对上述概念进行组合，就产生了如下的混淆矩阵：

<img src="https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5pz3RKU3MNoffCTZk6oUkEepjSmj0iaTmXmVHdy6qM2G2IdZERfUb6GgwStj7j8sGEUqWym9JYXfEw/0?wx_fmt=png&amp;" style="zoom:50%;" />

**然后**，由此引出True Positive Rate（真阳率）、False Positive（假阳率）两个概念：

- 真阳率：所有真实类别为1的样本中，预测为1的比例，相当于查全率

$$
TPR = \frac{TP}{TP+FN}
$$

- 假阳率：所有真实类别为0的样本中，预测为1的比例，假警报率

$$
FPR = \frac{FP}{FP+TN}
$$

**如何绘制ROC曲线？**

ROC曲线以假阳率为横坐标，真阳率为纵坐标。对于给定样例，根据学习器预测结果从大到小对样例进行排序，然后把分类阈值设为最大，即把全部样例均预测为反例，此时真阳率和假阳率均为0，坐标$(0,0)$对应ROC曲线第一个点。然后将分类阈值依次设为每一个样例的预测值，并在坐标系中绘制相应的点$(FPR,TPR)$，最后这些点连起来组成了ROC曲线。

**若一个学习器的ROC曲线被另一个学习器的曲线完全包住则可以断言后者的性能优于前者。**

**什么是AUC？**

按照定义，AUC即ROC曲线下的面积。AUC是一个模型评价指标，只能用于二分类模型的评价，AUC越大，模型性能越好。

<img src="https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5pz3RKU3MNoffCTZk6oUkEeJOj8cs072ibRiaAYlxgicXZaAF7IMs3ehnnznGGmc1rrcIJD81Ee2YnPQ/0?wx_fmt=png&amp;" style="zoom:70%;" />

### 2.2 PR曲线

PR曲线实则是以precision（精准率）和recall（召回率）这两个为变量而做出的曲线，其中recall为横坐标，precision为纵坐标。
**那么问题来了，什么是精确率？什么是召回率？**

- 精确率：所有预测为1的样本中，真实类别为1的比例，相当于查准率
  $$
  Precision = \frac{TP}{TP + FP}
  $$

- 召回率：所有真实类别为1的样本中，预测为1的比例，相当于查全率
  $$
  Recall = \frac{TP}{TP+FN}
  $$

**如何绘制PR曲线？**

PR曲线以召回率为横坐标，精确率为纵坐标。对于给定样例，根据学习器预测结果从大到小对样例进行排序，然后把分类阈值设为最大，即把全部样例均预测为反例，此时召回率和精确率均为0，坐标$(0,0)$对应PR曲线第一个点。然后将分类阈值依次设为每一个样例的预测值，并在坐标系中绘制相应的点$(Recall,Precision)$，最后这些点连起来组成了PR曲线。

<img src="https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5pz3RKU3MNoffCTZk6oUkEePrgf31941cIHnaeTtNFFMFSvIYj1oad3gkyVW8gOyiaj6JZTwQCEaHg/0?wx_fmt=png&amp;" style="zoom:80%;" />

**如果一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可断言后者的性能优于前者，例如上面的A和B优于学习器C。**但是A和B的性能无法直接判断，我们可以根据曲线下方的面积大小来进行比较，但更常用的是平衡点或者是$F_1$值。平衡点（BEP）是精确率=召回率时的取值，如果这个值较大，则说明学习器的性能较好。而$F_1  =  \frac {2 \cdot P \cdot R} {( P + R )}$，同样，$F_1$值越大，可以认为该学习器的性能较好。

### 2.3 Precision@n

假设样本正好有n个正例对应的precision。

对于不平衡数据集来说，正样本的数量本来就少，预测结果前几项的准确性比较重要，假设预测结果前几项的precision很低，那么后面的预测结果的准确性也不会高，模型意义不大。因此，需要一些指标来度量前几个结果的准确率，P@N就是这样一种指标。

**怎么来计算P@N的值呢？**

对于给定样例，根据学习器预测结果从大到小对样例进行排序，将第n个样例对应的预测结果作为分类阈值，计算前n个样例预测结果对应的precision。

### 2.4 Average precision

Average precision，也叫做平均精度，简称AP，主要描述了precision的一般表现，在异常检测中经常用到。

**怎么计算AP？**

简单来说就是对PR曲线上的Precision值求均值。
$$
AP = \frac{\sum_{i=1}^{n}{p(r_i)}}{n}
$$
其中，$n$是样本个数。在实际应用中，我们并不直接使用$r_i$对应的precision值，而是对PR曲线进行平滑处理。即对PR曲线上的每个点，Precision的值取该点右侧最大的Precision的值。$p(r_i)$的计算方式如下：
$$
p_{smooth}(r_i) = \mathop{\max}_{r>r_i}p(r)
$$

## 3 如何解决样本不均衡问题？

### 3.1 采样法

通过采样来调整数据不均衡，常用的采样方法分两类：欠采样和过采样。

下面将对这两类方法进行可视化展示。数据集来自使用Cardiotocogrpahy Dataset，分娩心电图描记法数据集，原始数据集大小为`2126*21`：2126条数据，每条数据有21个特征。其中正例197个，占比9.2662%，负例1929个，占比90.7338%，属于典型的样本不均衡分类。

笔者将原始数据采样处理后，进行可视化如下图。因为原始数据是21维不易直观展示，所以笔者使用TSNE把数据嵌入到2维空间进行可视化。图中黄色表示正例，蓝色表示反例。设置透明度后，数据重叠会加深颜色，甚至会造成颜色混合。左上、右上、左下、右下分别表示：

- 原始数据（Original）：未经任何采样处理的数据`2126*21`
- 欠采样（UnderSample）：使用随机欠采样，从反例中随机选择197个数据，与正例合并`394*21`
- 过采样（OverSample）：从正例中反复抽取生成2126个数据（大量重复），与反例合并`3858*21`
- SMOTE：也是一种过采样方法。通过找到正例中数据的近邻（相似），来合成新的`1929-197=1732`个新正例，并与原始数据合并`3858*21`，这里的并不是简单的重复，而是基于原始数据的生成，类似这样的算法还有很多，不再赘述。

![](https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5rJEoeBJW6v6kSdQPs6JGhzB4xBichA4DibXhCGc6ZXq2ywjXfpI835aEPlctnNic3w9iby9Ljhib1ph1Q/0?wx_fmt=png)

由图可见：

- 欠采样（右上）抛弃了大部分反例数据，弱化了绝大部分反例的影响，可能会造成偏差很大的模型。当然，如果数据不平衡，但是两个类别基数都非常大，那么影响可能不大。但是，数据是宝贵的，抛弃数据是很奢侈的，因此可以结合集成学习的思想，比如对反例进行反复欠采样，与正例组成n个平衡数据集，然后对这n个数据集分别训练模型，由n个预测结果集成出最终预测结果（类似随机森林）。这样可以使数据得到充分例用，但也有缺点：1）训练多个模型造成了更大的开销；2）正例被反复使用容易造成过拟合。

- 过采样（左下）只是单纯的重复使用了正例，因此会过分强调正例的重要性，如果正例其中有异常点或者标记错误，错误也会被放大，容易造成模型过拟合。

- SMOTE（右下）可以看出和过采样（左下）明显不同，因为不单单是重复使用正例，而且在局部通过KNN生成了新的正例，相较于普通过采样有如下特点：1）降低了过拟合风险。K近邻在局部合成数据，可以降低方差。但是也有可能错误的加强了局部的偶然性（如下图），从而增加过拟合的风险，总得来看，优点大于缺点；2）运算开销变大

  ![](https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5rJEoeBJW6v6kSdQPs6JGhzn6B5qYOibNTWZwx1ZX0E996yRWM2mFKhb5XS9cuuvv8gE1XwUv0tuLg/0?wx_fmt=png)

**实际应用中采样法的特点归纳：**

- 采样法一般比直接调整分类阈值效果好
- 采样法一般可以提高模型泛化能力，但是有过拟合风险，需要搭配正则化等降低过拟合的手段
- 过采样通常比欠采样效果好。但是也有可能错误地加强了异常点的重要性，在异常点较多时结果可能更差。
- 过采样会增大计算开销。

