**写在前面**：笔者前段时间又出差了，一周连续四天上线发版本，累成dog，于是公众号又停滞了。言归正传，本文谈的样本不均衡问题是机器学习中的常见问题，笔者之前几乎每次面试都会问到，这次好好梳理一下做个记录。

## 1 问题背景

机器学习中常常会遇到数据的**类别不平衡（class imbalance）**问题。以二分类问题为例，我们希望根据病人的一些检测指标预测病人是否得了某种罕见疾病。显然，根据所有历史数据，病人患这种罕见疾病的比例很低（不然咋叫罕见呢）。

在这种情况下，学习出好的分类器是很难的，得到的结论往往也是很具迷惑性的。因为如果一个分类器**总是**预测一个人未患罕见疾病，依然有高达99.9%的预测准确率（测试集与总体数据集同分布的情况下），看起来准确率很高，但却预测不出患病的病人。显然这种分类器是没有意义的，但它也反映了一个很重要的问题：**如何在类别不平衡的情况下评估分类器的性能？**

## 2 如何在类别不平衡的情况下评估分类器的性能？

对于平衡的数据，我们一般用准确率（accuracy）作为一般的评估标准。这种标准的默认假设前提是：**数据是平衡的，正例与反例的重要性一样，二分类器的阈值是0.5。**在这种情况下，用准确率来对分类器进行评估是合理的。

而当类别不平衡时，准确率就非常具有迷惑性，意义不大。下面给出几种主流的评估方法：

- ROC曲线，全名receiver operating characteristic curve，计算ROC曲线下的面积AUC是一种主流方法
- PR曲线，全名Precision-recall curve，和ROC有相似的地方，但定义不同，计算此曲线下的面积也是一种方法
- Precision@n是另一种方法，特制将分类阈值设定得到恰好n个正例时分类器的precision
- AP，全名Average precision，也叫做平均精度，主要描述了precision的一般表现，在异常检测中有时候会用
- 直接使用Precision也是一种想法，但需要调整分类器阈值（不要盲目使用0.5）

### 2.1 ROC曲线和AUC

ROC曲线指受试者工作特征曲线/接收器操作特性曲线(receiver operating characteristic curve), 是反映敏感性和特异性连续变量的综合指标,是用构图法揭示敏感性和特异性的相互关系，它通过将连续变量设定出多个不同的临界值，从而计算出一系列敏感性和特异性，再以敏感性为纵坐标、（1-特异性）为横坐标绘制成曲线，曲线下面积越大，诊断准确性越高。在ROC曲线上，最靠近坐标图左上方的点为敏感性和特异性均较高的临界值。