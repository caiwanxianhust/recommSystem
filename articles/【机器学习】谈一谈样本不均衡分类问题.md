**写在前面**：笔者前段时间又出差了，一周连续四天上线发版本，累成dog，于是公众号又停滞了。言归正传，本文谈的样本不均衡问题是机器学习中的常见问题，笔者之前几乎每次面试都会问到，这次好好梳理一下做个记录。这篇文章写了好长时间，总算初步完成了，写着写着就想开一个异常检测的版块了，学习下异常检测相关的算法了，先这样吧，溜了溜了~~

## 1 问题背景

机器学习中常常会遇到数据的**类别不平衡（class imbalance）**问题。以二分类问题为例，我们希望根据病人的一些检测指标预测病人是否得了某种罕见疾病。显然，根据所有历史数据，病人患这种罕见疾病的比例很低（不然咋叫罕见呢）。

在这种情况下，学习出好的分类器是很难的，得到的结论往往也是很具迷惑性的。因为如果一个分类器**总是**预测一个人未患罕见疾病，依然有高达99.9%的预测准确率（测试集与总体数据集同分布的情况下），看起来准确率很高，但却预测不出患病的病人。显然这种分类器是没有意义的，但它也反映了一个很重要的问题：类别不均衡时用准确率这种指标评估模型性能是不靠谱的。那么**如何在类别不平衡的情况下评估分类器的性能？**

## 2 如何在类别不平衡的情况下评估分类器的性能？

对于平衡的数据，我们一般用准确率（accuracy）作为一般的评估标准。这种标准的默认假设前提是：**数据是平衡的，正例与反例的重要性一样，二分类器的阈值是0.5。**在这种情况下，用准确率来对分类器进行评估是合理的。

而当类别不平衡时，准确率就非常具有迷惑性，意义不大。下面给出几种主流的评估方法：

- ROC曲线，全名receiver operating characteristic curve，计算ROC曲线下的面积AUC是一种主流方法
- PR曲线，全名Precision-recall curve，和ROC有相似的地方，但定义不同，计算此曲线下的面积也是一种方法
- Precision@n是另一种方法，特制将分类阈值设定得到恰好n个正例时分类器的precision
- AP，全名Average precision，也叫做平均精度，主要描述了precision的一般表现，在异常检测中有时候会用
- 直接使用Precision也是一种想法，但需要调整分类器阈值（不要盲目使用0.5）

### 2.1 ROC曲线和AUC

ROC曲线，即受试者工作特征曲线（receiver operating characteristic curve），是反映敏感性和特异性连续变量的综合指标。

**首先**，在试图弄懂AUC和ROC曲线之前，一定，一定要彻底理解**混淆矩阵**的定义！！！

混淆矩阵中有着Positive、Negative、True、False的概念，其含义如下：

- **称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）。**
- **预测正确的为True（真），预测错误的为False（假）。**

对上述概念进行组合，就产生了如下的混淆矩阵：

<img src="https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5pz3RKU3MNoffCTZk6oUkEepjSmj0iaTmXmVHdy6qM2G2IdZERfUb6GgwStj7j8sGEUqWym9JYXfEw/0?wx_fmt=png&amp;" style="zoom:50%;" />

**然后**，由此引出True Positive Rate（真阳率）、False Positive（假阳率）两个概念：

- 真阳率：所有真实类别为1的样本中，预测为1的比例，相当于查全率

$$
TPR = \frac{TP}{TP+FN}
$$

- 假阳率：所有真实类别为0的样本中，预测为1的比例，假警报率

$$
FPR = \frac{FP}{FP+TN}
$$

**如何绘制ROC曲线？**

ROC曲线以假阳率为横坐标，真阳率为纵坐标。对于给定样例，根据学习器预测结果从大到小对样例进行排序，然后把分类阈值设为最大，即把全部样例均预测为反例，此时真阳率和假阳率均为0，坐标$(0,0)$对应ROC曲线第一个点。然后将分类阈值依次设为每一个样例的预测值，并在坐标系中绘制相应的点$(FPR,TPR)$，最后这些点连起来组成了ROC曲线。

**若一个学习器的ROC曲线被另一个学习器的曲线完全包住则可以断言后者的性能优于前者。**

**什么是AUC？**

按照定义，AUC即ROC曲线下的面积。AUC是一个模型评价指标，只能用于二分类模型的评价，AUC越大，模型性能越好。

<img src="https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5pz3RKU3MNoffCTZk6oUkEeJOj8cs072ibRiaAYlxgicXZaAF7IMs3ehnnznGGmc1rrcIJD81Ee2YnPQ/0?wx_fmt=png&amp;" style="zoom:70%;" />

### 2.2 PR曲线

PR曲线实则是以precision（精准率）和recall（召回率）这两个为变量而做出的曲线，其中recall为横坐标，precision为纵坐标。
**那么问题来了，什么是精确率？什么是召回率？**

- 精确率：所有预测为1的样本中，真实类别为1的比例，相当于查准率
  $$
  Precision = \frac{TP}{TP + FP}
  $$

- 召回率：所有真实类别为1的样本中，预测为1的比例，相当于查全率
  $$
  Recall = \frac{TP}{TP+FN}
  $$

**如何绘制PR曲线？**

PR曲线以召回率为横坐标，精确率为纵坐标。对于给定样例，根据学习器预测结果从大到小对样例进行排序，然后把分类阈值设为最大，即把全部样例均预测为反例，此时召回率和精确率均为0，坐标$(0,0)$对应PR曲线第一个点。然后将分类阈值依次设为每一个样例的预测值，并在坐标系中绘制相应的点$(Recall,Precision)$，最后这些点连起来组成了PR曲线。

<img src="https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5pz3RKU3MNoffCTZk6oUkEePrgf31941cIHnaeTtNFFMFSvIYj1oad3gkyVW8gOyiaj6JZTwQCEaHg/0?wx_fmt=png&amp;" style="zoom:80%;" />

**如果一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可断言后者的性能优于前者，例如上面的A和B优于学习器C。**但是A和B的性能无法直接判断，我们可以根据曲线下方的面积大小来进行比较，但更常用的是平衡点或者是$F_1$值。平衡点（BEP）是精确率=召回率时的取值，如果这个值较大，则说明学习器的性能较好。而$F_1  =  \frac {2 \cdot P \cdot R} {( P + R )}$，同样，$F_1$值越大，可以认为该学习器的性能较好。

### 2.3 Precision@n

假设样本正好有n个正例对应的precision。

对于不平衡数据集来说，正样本的数量本来就少，预测结果前几项的准确性比较重要，假设预测结果前几项的precision很低，那么后面的预测结果的准确性也不会高，模型意义不大。因此，需要一些指标来度量前几个结果的准确率，P@N就是这样一种指标。

**怎么来计算P@N的值呢？**

对于给定样例，根据学习器预测结果从大到小对样例进行排序，将第n个样例对应的预测结果作为分类阈值，计算前n个样例预测结果对应的precision。

### 2.4 Average precision

Average precision，也叫做平均精度，简称AP，主要描述了precision的一般表现，在异常检测中经常用到。

**怎么计算AP？**

简单来说就是对PR曲线上的Precision值求均值。
$$
AP = \frac{\sum_{i=1}^{n}{p(r_i)}}{n}
$$
其中，$n$是样本个数。在实际应用中，我们并不直接使用$r_i$对应的precision值，而是对PR曲线进行平滑处理。即对PR曲线上的每个点，Precision的值取该点右侧最大的Precision的值。$p(r_i)$的计算方式如下：
$$
p_{smooth}(r_i) = \mathop{\max}_{r>r_i}p(r)
$$

## 3 如何解决样本不均衡问题？

### 3.1 采样法

通过采样来调整数据不均衡，常用的采样方法分两类：欠采样和过采样。

下面将对这两类方法进行可视化展示。数据集来自使用Cardiotocogrpahy Dataset，分娩心电图描记法数据集，原始数据集大小为`2126*21`：2126条数据，每条数据有21个特征。其中正例197个，占比9.2662%，负例1929个，占比90.7338%，属于典型的样本不均衡分类。

笔者将原始数据采样处理后，进行可视化如下图。因为原始数据是21维不易直观展示，所以笔者使用TSNE把数据嵌入到2维空间进行可视化。图中黄色表示正例，蓝色表示反例。设置透明度后，数据重叠会加深颜色，甚至会造成颜色混合。代码如下：

```python
import numpy as np
from sklearn.manifold import TSNE
from matplotlib import pyplot as plt
import seaborn as sns
import pandas as pd
import imblearn

sns.set(rc={'figure.figsize':(11.7,8.27)})
palette = sns.color_palette("bright", 2)

cardio = pd.read_csv("./cardio_origin_data.csv")
cardio.shape   # [5 rows x 22 columns]  (2126, 22))

# 正例数量
len(cardio.loc[cardio.SUSP > 0])   # 197

# 原始数据tsne转换
tsne = TSNE(n_components=2, init='pca')
X_embedded = tsne.fit_transform(cardio.iloc[:,:-1])

# 欠采样
#通过设置RandomUnderSampler中的replacement=True参数, 可以实现自助法(boostrap)抽样
#通过设置RandomUnderSampler中的ratio参数,可以设置数据采样比例
rus = imblearn.under_sampling.RandomUnderSampler(1, 
                                                 random_state=0, 
                                                 replacement=True) #采用随机欠采样（下采样）
X_undersample_embedded, y_undersample_embedded = rus.fit_sample(X_embedded, cardio.iloc[:, -1])

# 随机过采样
ros = imblearn.over_sampling.RandomOverSampler(1, random_state=0) 
X_oversample_embedded, y_oversample_embedded = ros.fit_sample(X_embedded, cardio.iloc[:, -1])

# smote采样
ros = imblearn.over_sampling.SMOTE(1, random_state=0) 
X_smotesample_embedded, y_smotesample_embedded = ros.fit_sample(X_embedded, cardio.iloc[:, -1])
y_smotesample_embedded[y_smotesample_embedded == 1].shape

# 绘图
fig,ax = plt.subplots(2, 2,figsize=(20, 20))
f_origin = sns.scatterplot(X_embedded[:,0], X_embedded[:,1], 
                hue=cardio.iloc[:,-1], 
                legend='full', palette=palette, alpha = 2/5, ax=ax[0,0])
f_origin.set_title(label = 'Original')

f_undersample = sns.scatterplot(X_undersample_embedded[:,0], X_undersample_embedded[:,1], 
                hue=y_undersample_embedded, 
                legend='full', palette=palette, alpha = 2/5, ax=ax[0,1])
f_undersample.set_title(label = 'UnderSample')

f_oversample = sns.scatterplot(X_oversample_embedded[:,0], X_oversample_embedded[:,1], 
                hue=y_oversample_embedded, 
                legend='full', palette=palette, alpha = 2/5, ax=ax[1,0])
f_oversample.set_title(label = 'OverSample')

f_smotesample = sns.scatterplot(X_smotesample_embedded[:,0], X_smotesample_embedded[:,1], 
                hue=y_smotesample_embedded, 
                legend='full', palette=palette, alpha = 2/5, ax=ax[1,1])
f_smotesample.set_title(label = 'SmoteSample')
```

左上、右上、左下、右下分别表示：

- 原始数据（Original）：未经任何采样处理的数据`2126*21`
- 欠采样（UnderSample）：使用随机欠采样，从反例中随机选择197个数据，与正例合并`394*21`
- 过采样（OverSample）：从正例中反复抽取生成2126个数据（大量重复），与反例合并`3858*21`
- SMOTE：也是一种过采样方法。通过找到正例中数据的近邻（相似），来合成新的`1929-197=1732`个新正例，并与原始数据合并`3858*21`，这里的并不是简单的重复，而是基于原始数据的生成，类似这样的算法还有很多，不再赘述。

![](https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5rJEoeBJW6v6kSdQPs6JGhzB4xBichA4DibXhCGc6ZXq2ywjXfpI835aEPlctnNic3w9iby9Ljhib1ph1Q/0?wx_fmt=png)

由图可见：

- 欠采样（右上）抛弃了大部分反例数据，弱化了绝大部分反例的影响，可能会造成偏差很大的模型。当然，如果数据不平衡，但是两个类别基数都非常大，那么影响可能不大。但是，数据是宝贵的，抛弃数据是很奢侈的，因此可以结合集成学习的思想，比如对反例进行反复欠采样，与正例组成n个平衡数据集，然后对这n个数据集分别训练模型，由n个预测结果集成出最终预测结果（类似随机森林）。这样可以使数据得到充分例用，但也有缺点：1）训练多个模型造成了更大的开销；2）正例被反复使用容易造成过拟合。

- 过采样（左下）只是单纯的重复使用了正例，因此会过分强调正例的重要性，如果正例其中有异常点或者标记错误，错误也会被放大，容易造成模型过拟合。

- SMOTE（右下）可以看出和过采样（左下）明显不同，因为不单单是重复使用正例，而且在局部通过KNN生成了新的正例，相较于普通过采样有如下特点：1）降低了过拟合风险。K近邻在局部合成数据，可以降低方差。但是也有可能错误的加强了局部的偶然性（如下图），从而增加过拟合的风险，总得来看，优点大于缺点；2）运算开销变大

  ![](https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5rJEoeBJW6v6kSdQPs6JGhzn6B5qYOibNTWZwx1ZX0E996yRWM2mFKhb5XS9cuuvv8gE1XwUv0tuLg/0?wx_fmt=png)

**实际应用中采样法的特点归纳：**

- 采样法一般比直接调整分类阈值效果好
- 采样法一般可以提高模型泛化能力，但是有过拟合风险，需要搭配正则化等降低过拟合的手段
- 过采样通常比欠采样效果好。但是也有可能错误地加强了异常点的重要性，在异常点较多时结果可能更差。作为一种升级版的过采样，SMOTE也是不错的处理方式。
- 过采样会增大计算开销。

### 3.2 集成学习方法
可以先用采样的方法建立k个平衡的训练集，每个训练集上单独训练⼀个分类器，并对k个分类器结果取平均。⼀般在这种情况下，每个平衡训练集上都需要使用比较简单的分类器，如逻辑回归。其实在实际使用中，这种方法不一定会比集成树模型更好，可能还不如直接使用xgboost。但在复杂问题上多尝试一些手段是好的，可以作为一个baseline。 

### 3.3 无监督的异常检测方法

异常检测指的是从数据中找到那些异常值，无监督的异常检测一般依赖于对数据的假设，比如垃圾邮件和正常邮件的内容很不相同、阳性病例的体检报告和阴性病例的体检报告有显著差异，那么可以有一种假设：正负样本向量间的欧氏距离很大。无监督异常检测最大优势就是**不需要数据标签**，而且如果对数据假设正确的情况下其效果甚至可以比监督学习更好。

无监督异常检测模型大致可以分为以下几类：

- 概率统计模型（statistical and probabilistic and models）：对数据的分布作出假设，并找出该假设下定义的”异常“，此方法往往会使用极值分析或者假设检验。比如对简单的一维数据假设其服从高斯分布，然后将距离均值特定范围以外的数据当作异常点。推广到高维后，可以用马氏距离（mahalanobis distance）将变量按主成分进行旋转，让维度间相互独立，然后再进行标准化处理，让各个维度方差均值统一，这个时候欧式距离就是马氏距离，最后计算各个维度上的异常度之和即可。可以看出这类方法最大的好处就是计算速度快，但是由于假设未必正确所以其效果不一定很好。
- 线性模型（linear models）：将样本嵌入到低维空间，在低维空间上的离群点认为是异常点。举个例子，使用PCA找到样本集的k个特征向量，计算每个样本经过K个特征向量投射后的重建误差，正常点的重建误差应该小于异常点。同理也可以计算每个样本到这k个特征向量所构成得超空间得加权欧氏距离（特征值越小权重越大）。
- 基于相似度衡量得模型（proximity based models）:异常点和正常点的分布不同，因此相似度较低，衍生了一系列算法通过相似度来识别异常点。比如最简单的K近邻，用样本和它第K个近邻的距离作为衡量标准，显然异常点的K近邻距离更大。还有基于密度分析的LOF、LOCI和LoOP，通过局部密度来检测异常，因为异常点所在的空间数据点少，密度更小。还有一种ABOD算法通过计算每个样本与所有其他样本对所形成的夹角的方差，异常点由于远离正常点方差变化小。
- 集成异常检测与模型融合：在无监督学习时，提高模型的鲁棒性很重要，因此通常结合集成学习使用。最早的集成检测框架feature bagging与随机森林很像，先将训练数据随机划分（每次选取所有样本的部分特征），得到多个子训练集，再在每个训练集上训练一个独立模型（默认为LOF）并最终合并所有的模型结果。

总的来说，上面的方法其实是互相联系的。比如K近邻可以看作一种概率模型；通过马氏距离计算异常度也假设了数据服从高斯分；计算重建误差除了PCA还可以用神经网络自编码器。

### 3.4 **半监督异常集成学习**

把集成学习和无监督异常检测的思路结合起来，称为半监督异常集成学习。具体来说，先在原始数据集上使用多个无监督异常检测方法来抽取数据的表示，并和原始的数据结合作为新的特征空间。在新的特征空间上使用集成树模型，如xgboost，来进行监督学习。无监督异常检测的作用是提高原始数据的特征表达（相当于一次特征工程），监督集成树的目的是降低数据不平衡对于最终预测结果的影响。当然，这个方法最大的问题是**运算开销比较大**，需要进行深度优化。

## 4 异常检测第三方库PyOD

### 4.1 API介绍

特别需要注意的是，异常检测算法基本都是无监督学习，所以只需要X（输入数据），而不需要y（标签）。PyOD的使用方法和Sklearn中聚类分析很像，它的检测器（detector）均有统一的API接口。  

- fit(X)：用数据X来“训练/拟合”检测器clf。即在初始化检测器clf后，用X来“训练”它。
- fit_predict_score(X, y)：用数据X来训练检测器clf，并预测X的预测值，并在真实标签y上进行评估。此处的y只是用于评估，而非训练
- decision_function(X)：在检测器clf被fit后，可以通过该函数来预测未知数据的异常程度，返回值为原始分数，并非0和1。返回分数越高，则该数据点的异常程度越高
- predict(X)：在检测器clf被fit后，可以通过该函数来预测未知数据的异常标签，返回值为二分类标签（0为正常点，1为异常点）
- predict_proba(X)：在检测器clf被fit后，预测未知数据的异常概率，返回该点是异常点概率
  

当检测器clf被初始化且fit(X)函数被执行后，clf就会生成两个重要的属性：  
- decision_scores：数据X上的异常打分，分数越高，则该数据点的异常程度越高

- labels：数据X上的异常标签，返回值为二分类标签（0为正常点，1为异常点。  

不难看出，当我们初始化一个检测器clf后，可以直接用数据X来“训练”clf，之后便可以得到X的异常分值（clf.decision_scores）以及异常标签（clf.labels_）。当clf被训练后（当fit函数被执行后），还可以使用decision_function()和predict()函数来对未知数据进行训练。

### 4.2 示例

#### 4.2.1 导入库

使用HBOS算法进行异常检测。

```python
import pandas as pd
import numpy as np
# from pyod.models.mcd import MCD
# from pyod.models.knn import KNN
from pyod.models.hbos import HBOS
# from sklearn.model_selection import train_test_split
from pyod.utils.data import generate_data, evaluate_print
from pyod.utils.example import visualize
from sklearn.manifold import TSNE
```

#### 4.2.2 生成样本

使用`generate_data`函数生成异常检测样本。样本特征设为10维，异常点占比10%。

```python
contamination = 0.1  # percentage of outliers
n_train = 700  # number of training points
n_test = 300  # number of testing points
n_features = 10  # dim of features

X_train, y_train, X_test, y_test = generate_data(n_train=n_train, 
                                                 n_test=n_test,
                                                 n_features=n_features,
                                                 contamination=contamination)
X_train.shape, y_test.shape
# ((700, 10), (300,))
```

#### 4.2.3 模型训练

示例而已，就不调参了。

```python
clf = HBOS()
clf.fit(X_train)

# 返回训练数据X_train上的异常标签和异常分值
y_train_pred = clf.labels_  # 返回训练数据上的分类标签 (0: 正常值, 1: 异常值)
y_train_scores = clf.decision_scores_  # 返回训练数据上的异常值 (分值越大越异常)

# 用训练好的clf来预测未知数据中的异常值
y_test_pred = clf.predict(X_test)  # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值)
y_test_scores = clf.decision_function(X_test)  #  返回未知数据上的异常值 (分值越大越异常)
```

#### 4.2.4 模型评估与可视化

```python
# 评估预测结果
print("\nOn Training Data:")
evaluate_print("HBOS", y_train, y_train_pred)
print("\nOn Test Data:")
evaluate_print("HBOS", y_test, y_test_pred)

# 使用tsne算法把10维特征映射到2维空间
tsne = TSNE(n_components=2, init='pca')
X_embedded = tsne.fit_transform(np.concatenate((X_train, X_test), axis=0))
X_train_embedded = X_embedded[:700, :]
X_test_embedded = X_embedded[700:, :]

# 可视化
visualize("HBOS", X_train_embedded, y_train, X_test_embedded, y_test, y_train_pred, y_test_pred, show_figure=True, save_figure=False)
```

毕竟是自己生成的数据嘛，效果还行吧。

```python
On Training Data:
HBOS ROC:0.9286, precision @ rank n:0.8714

On Test Data:
HBOS ROC:0.913, precision @ rank n:0.9259
```

![](https://mmbiz.qpic.cn/mmbiz_png/GJUG0H1sS5ptzZ973EChRFg8HEJFpWa6VkHAqSQH0INlGnVQTAPrrj8z3picvvdGicqUEqyJWMiaeRSPqHN7EI8kA/0?wx_fmt=png)
